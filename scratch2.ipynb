{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import decomposition\n",
    "\n",
    "class Model:  \n",
    "    \"\"\"\n",
    "    This class represents an AI model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor for Model class.\n",
    "  \n",
    "        Parameters\n",
    "        ----------\n",
    "        self : object\n",
    "            The instance of the object passed by Python.\n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own initialization code.\n",
    "        self.nancolumns = ['V39','V38', 'V15', 'V5','V47']\n",
    "        # self.large_cat_features = ['V12', 'V21', 'V24', 'V29', 'V36', 'V37', 'V51', 'V52', 'V55', 'V58']\n",
    "        # self.small_cat_features = ['V9', 'V19', 'V20', 'V23', 'V31', 'V46', 'V54']\n",
    "        self.numerical_features = ['V0', 'V1', 'V10', 'V11', 'V13', 'V14', 'V16', 'V17', 'V18', 'V2',\n",
    "                            'V22', 'V25', 'V26', 'V27', 'V28', 'V3', 'V30', 'V32', 'V33', 'V34',\n",
    "                            'V35', 'V4', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V48', 'V49',\n",
    "                            'V50', 'V53', 'V56', 'V57', 'V59', 'V6', 'V7', 'V8']\n",
    "        self.categorical_features = ['V9', 'V12', 'V19', 'V20', 'V21', 'V23', 'V24', 'V29', 'V31', 'V36',\n",
    "       'V37', 'V46', 'V51', 'V52', 'V54', 'V55', 'V58']\n",
    "        \n",
    "\n",
    "        self.large_cat_features = ['V12', 'V21', 'V24', 'V37']\n",
    "        self.small_cat_features = ['V9', 'V19', 'V20', 'V23', 'V29', 'V31', 'V36', 'V46', 'V51', 'V52', 'V54', 'V55', 'V58']\n",
    "    \n",
    "    def fit(self, X_dict, y):\n",
    "        \"\"\"\n",
    "        Train the model using the input data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_dict : dictionary with the following entries:\n",
    "            - tabular: pandas Dataframe of shape (n_samples, n_features)\n",
    "            - images: ndarray of shape (n_samples, height, width)\n",
    "            Training data.\n",
    "        y : pandas Dataframe of shape (n_samples,)\n",
    "            Target values.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of the trained model.\n",
    "        \"\"\"\n",
    "        # TODO: Add your training code.\n",
    "        tabular = X_dict['tabular']\n",
    "        images = X_dict['images']\n",
    "\n",
    "        images = images.reshape(images.shape[0], -1)\n",
    "        image_labels = ['T' + str(i) for i in range(images.shape[1])]\n",
    "        image_df = pd.DataFrame(images, columns=image_labels)\n",
    "\n",
    "        tabular = tabular.drop(columns=self.nancolumns)\n",
    "\n",
    "        tabular.reset_index(drop=True, inplace=True)\n",
    "        image_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # print(tabular.shape)\n",
    "        # print(image_df.shape)\n",
    "        combined = pd.concat([tabular, image_df], axis=1)\n",
    "        # combined = tabular\n",
    "\n",
    "\n",
    "        print(self.numerical_features + self.categorical_features)\n",
    "        combined = combined.dropna(subset=self.numerical_features + self.categorical_features)\n",
    "        y = y[combined.index]\n",
    "\n",
    "        numeric_transformer = Pipeline( \n",
    "            steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "                   (\"scaler\", StandardScaler()),\n",
    "                   (\"pca\", decomposition.PCA(n_components=10, svd_solver='full'))\n",
    "            ]\n",
    "        ) \n",
    " \n",
    "        small_cat_transformer = Pipeline( \n",
    "            steps=[ \n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")), \n",
    "            ] \n",
    "        ) \n",
    "\n",
    "        large_cat_transformer = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"encoder\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        image_transformer = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy='constant', fill_value=0)),\n",
    "                (\"pca\", decomposition.PCA(n_components=10, svd_solver='full'))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pca = decomposition.PCA(n_components=15, svd_solver='full')\n",
    "\n",
    "        preprocessor = ColumnTransformer( \n",
    "            transformers=[ \n",
    "                (\"num\", numeric_transformer, self.numerical_features), \n",
    "                (\"small_cat\", small_cat_transformer, self.small_cat_features), \n",
    "                (\"large_cat\", large_cat_transformer, self.large_cat_features),\n",
    "                (\"image\", image_transformer, image_labels)\n",
    "            ] \n",
    "        ) \n",
    "\n",
    "        self.model = Pipeline( \n",
    "            steps=[\n",
    "                (\"preprocessor\", preprocessor),\n",
    "                (\"pca\", pca),\n",
    "                # (\"regressor\", LinearRegression())\n",
    "                (\"regressor\", RandomForestRegressor(\n",
    "                    random_state=42, n_estimators=5,\n",
    "                    max_depth=5, min_samples_split=10, min_samples_leaf=5,\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "                 \n",
    "        ) \n",
    "\n",
    "        self.model.fit(combined, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_dict):\n",
    "        \"\"\"\n",
    "        Use the trained model to make predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_dict : dictionary with the following entries:\n",
    "            - tabular: pandas Dataframe of shape (n_samples, n_features)\n",
    "            - images: ndarray of shape (n_samples, height, width)\n",
    "            Input data.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pandas Dataframe of shape (n_samples,)\n",
    "           Predicted target values per element in X_dict.\n",
    "           \n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own prediction code.\n",
    "        tabular = X_dict['tabular']\n",
    "        images = X_dict['images']\n",
    "\n",
    "        images = images.reshape(images.shape[0], -1)\n",
    "        image_labels = ['T' + str(i) for i in range(images.shape[1])]\n",
    "        image_df = pd.DataFrame(images, columns=image_labels)\n",
    "\n",
    "        tabular = tabular.drop(columns=self.nancolumns)\n",
    "        tabular.reset_index(drop=True, inplace=True)\n",
    "        image_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        combined = pd.concat([tabular, image_df], axis=1)\n",
    "        # combined = tabular\n",
    "\n",
    "        return self.model.predict(combined)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from util import dict_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(os.path.join('data', 'tabular.csv'))\n",
    "with open(os.path.join('data', 'images.npy'), 'rb') as f:\n",
    "    images = np.load(f)\n",
    "    \n",
    "# Exclude target column\n",
    "X_columns = [col for col in df.columns if col != 'target']\n",
    "\n",
    "# Create X_dict and y\n",
    "X_dict = {\n",
    "    'tabular': df[X_columns],\n",
    "    'images': images\n",
    "}\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# Split train and test\n",
    "X_dict_train, y_train, X_dict_test, y_test = dict_train_test_split(X_dict, y, ratio=0.9)\n",
    "\n",
    "# Train and predict\n",
    "model = Model()\n",
    "model.fit(X_dict_train, y_train)\n",
    "y_pred = model.predict(X_dict_test)\n",
    "\n",
    "# Evaluate model predition\n",
    "# Learn more: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "print(\"MSE: {0:.2f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs2109s-2220-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
